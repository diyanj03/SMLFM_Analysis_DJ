from scipy.stats import linregress
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from scipy.optimize import curve_fit
import os
import pandas as pd


def extract_counts(tracks_dict):
    """
    Args:
    - tracks_dict (dict): Dictionary where keys represent tau_tl (unit: seconds) and values represent path to csv track files generated by SPT.

    Returns:
    - counts_dict (dict): 
        - keys are tau_interval and values represent a tuple:
        - element 1: histograms (counts) for all track lengths for all datasets with the same tau_interval.
        - element 2: total number of counts (sum of all track lengths) for that tau_interval.
        - element 3: number of FOVs from which counts were extracted for that tau_interval.
    """
    counts_dict = {}
    for tau_interval, tracks_folder in tracks_dict.items():
        numPos_concat = []
        numFOVs = 0
        for track_file_name in os.listdir(tracks_folder):
            if track_file_name.endswith('_positionsFramesIntensity.csv'):
                track_file_path = os.path.join(tracks_folder, track_file_name)
                df = pd.read_csv(track_file_path, comment='#')
                numPos_series = df.iloc[:, 1]
                numPos_concat.extend(numPos_series.tolist())
                numFOVs += 1
        
        if not numPos_concat:
            counts = np.array([], dtype='int64')
            total_counts = 0
        else:
            edges = np.arange(min(numPos_concat) - 0.5, max(numPos_concat) + 0.5 + 0.1, 1)
            counts, _ = np.histogram(numPos_concat, bins=edges)
            counts = np.array(counts).astype('int64')
            total_counts = np.sum(counts) 

        counts_dict[tau_interval] = (counts, total_counts, numFOVs)
    return counts_dict


def compute_keffs(counts_dict):
    """
    Input raw counts for each timelapse interval for calculating keffs.
    Args:
    - counts_dict (dict): Dictionary where keys represent tau_tl (unit: seconds) and values represent a list of raw counts for each frame.

    Returns:
    - keffs_dict (dict): keys are tau_interval and values represent a tuple of (k_eff, k_eff_sd_error)
    - fig (matplotlib object): plot of the exponential fittings
    """
    
    keff_dict = {}

    # exponential decay to fit data and model k_eff 
    def exp_decay(x, A, k_eff):
        return A * np.exp(-k_eff * x)
    
    fig, ax = plt.subplots()

    for tau_tl, value in counts_dict.items():
        counts = value[0]
        actual_x = np.arange(2, len(counts)+1.01, 1) * tau_tl
        fit_x = np.linspace(min(actual_x), max(actual_x), 200)
        
        # guessing initial A and k_eff using log transform fit
        valid = counts > 0
        actual_x_valid = actual_x[valid]
        counts_valid = counts[valid]
        log_counts = np.log(counts_valid)
        slope, intercept = np.polyfit(actual_x_valid, log_counts, 1)
        k_eff_guess = -slope
        A_guess = np.exp(intercept)
        p0 = [A_guess, k_eff_guess]

        # non linear LSE
        popt, pcov = curve_fit(exp_decay, actual_x, counts, p0=p0)
        
        A_fit, k_eff_fit = popt

        perr = np.sqrt(np.diag(pcov))  # standard errors
        A_err, k_eff_err = perr

        keff_dict[tau_tl] = (k_eff_fit, k_eff_err)

        scatter = ax.scatter(actual_x, counts, label=f'{tau_tl}s data')
        label = rf"{tau_tl}s fit: $k_{{\mathrm{{eff}}}} = {k_eff_fit:.3f} \pm {k_eff_err:.3f} \ \mathrm{{s^{{-1}}}}$"
        line, = ax.plot(fit_x, exp_decay(fit_x, A_fit, k_eff_fit),
                         label = label,
                         color = scatter.get_facecolors()[0])
        
    
    ax.set_xscale('log')
    ax.grid(which='both', linestyle='--', linewidth=0.5)
    ax.set_xlabel(r"n$\tau_{\mathrm{tl}}$ (seconds)")
    ax.set_ylabel("raw occurence")
    ax.legend()
    plt.show()

    # surviving fraction instead of raw counts
    fig2, ax2 = plt.subplots()

    for tau_tl, value in counts_dict.items():
        counts = value[0]
        total_counts = np.sum(counts)
        perc_surviving = counts / total_counts

        actual_x = np.arange(2, len(counts)+1.01, 1) * tau_tl
        fit_x = np.linspace(min(actual_x), max(actual_x), 200)
        
        valid = perc_surviving > 0
        actual_x_valid = actual_x[valid]
        perc_valid = perc_surviving[valid]
        log_perc = np.log(perc_valid)
        slope, intercept = np.polyfit(actual_x_valid, log_perc, 1)
        k_eff_guess = -slope
        A_guess = np.exp(intercept)
        p0 = [A_guess, k_eff_guess]

        popt, pcov = curve_fit(exp_decay, actual_x, perc_surviving, p0=p0)
        A_fit, k_eff_fit = popt
        perr = np.sqrt(np.diag(pcov))
        A_err, k_eff_err = perr

        scatter = ax2.scatter(actual_x, perc_surviving, label=f'{tau_tl}s data')
        
        label = rf"{tau_tl}s fit: $k_{{\mathrm{{eff}}}} = {k_eff_fit:.3f} \pm {k_eff_err:.3f} \ \mathrm{{s^{{-1}}}}$"

        ax2.plot(fit_x, exp_decay(fit_x, A_fit, k_eff_fit),
                label = label,
                color=scatter.get_facecolors()[0])

    ax2.set_xscale('log')
    ax2.grid(which='both', linestyle='--', linewidth=0.5)
    ax2.set_xlabel(r"n$\tau_{\mathrm{tl}}$ (seconds)")
    ax2.set_ylabel("fraction surviving")
    ax2.legend()
    plt.show()

    return keff_dict, fig, fig2


def compute_koffs(keff_dict, tau_int):
    """
    uses keffs for each timelapse interval and computes koff and kb.
    Args:
    - keff_dict (dict): Dictionary where keys represent tau_tl (unit: seconds) and values represent a tuple of (k_eff, k_eff_sd_error)
    - tau_int (float): camera integration time/exposure time in seconds.

    Returns:
    - rates (tuple): (dissociation_rate, photobleaching_rate) in seconds^-1
    - fit_metrics (tuple): (k_off_standard_error, r_square_value)
    - fig (matplotlib object): plot of the linear fit
    """
    tau_tl_list = np.array(list(keff_dict.keys()))
    keff_values = np.array(np.array([v[0] for v in keff_dict.values()]))
    keff_errors = np.array(np.array([v[1] for v in keff_dict.values()]))

    keff_tl_data = keff_values*tau_tl_list
    keff_tl_errors = keff_errors*tau_tl_list

    slope, intercept, r_value, p_value, koff_std_err = linregress(tau_tl_list, keff_tl_data)

    k_off = slope 
    c_b = intercept
    k_b = c_b / tau_int

    rates = (k_off, k_b)
    fit_metrics = (r_value**2, koff_std_err)

    t = np.linspace(0, max(tau_tl_list), 200)
    fit = k_off * t + c_b

    fig, ax = plt.subplots()

    k_off_annot = rf"$k_{{\mathrm{{off}}}} = {k_off:.3f} \pm {koff_std_err:.3f} \ \mathrm{{s^{{-1}}}}$"

    # plotting data first
    data_handle = ax.errorbar(tau_tl_list, keff_tl_data, yerr=keff_tl_errors,
                            fmt='o', color='black', capsize=3, elinewidth=1, label='Data ± SE')

    fit_handle, = ax.plot(t, fit, color='black', label=f'Linear fit: {k_off_annot}')

    ax.set_xlabel(r"$\tau_{\mathrm{tl}}$ (seconds)")
    ax.set_ylabel(r"$k_{\mathrm{eff}} \, \tau_{\mathrm{tl}}$")

    current_ylim = ax.get_ylim()
    ax.set_ylim(bottom=0, top=current_ylim[1])
    ax.grid()

    ax.legend(handles=[data_handle, fit_handle])


    return rates, fit_metrics, fig


def koff_kb_rates(tracks_dict, tau_int, sample_name, root_directory, destination_directory=None):
    """
    Residence time analysis using SPT data from timelapse experiments.
    Args:
    - tracks_dict (dict): Dictionary where keys represent tau_tl (unit: seconds) and values represent folder path to csv SPT files. 
    - tau_int (float): camera integration time/exposure time in seconds.
    - sample_name: name of sample/condition
    - root_directory
    - destination_directory (str, optional): path to custom destination 

    Outputs: 
    - exponential_fits plot
    - linear fit plot
    - txt of results and rates.
    """
    # defining destinaiton dir 
    if destination_directory:
        destination_dir = os.path.join(destination_directory, f'{sample_name}_residenceTimeAnalysis')
    else:
        destination_dir = os.path.join(root_directory, 'results', f'{sample_name}_residenceTimeAnalysis')
    os.makedirs(destination_dir, exist_ok=True)

    # calling all functions
    counts_dict = extract_counts(tracks_dict)
    keff_dict, expFit_fig1, expFit_fig2 = compute_keffs(counts_dict)
    rates, linFit_metrics, linFit_fig = compute_koffs(keff_dict, tau_int)
    
    # saving figures
    exp_fit1_destination = os.path.join(destination_dir, f'keff_expFits_rawOccurence.pdf')
    exp_fit2_destination = os.path.join(destination_dir, f'keff_expFits_fracSurviving.pdf' )
    expFit_fig1.savefig(exp_fit1_destination)
    expFit_fig2.savefig(exp_fit2_destination)
    lin_fit_destination = os.path.join(destination_dir, f'koff_kb_linFit.pdf')
    linFit_fig.savefig(lin_fit_destination)

    # txt to save/store results.
    txt_out = "=== Residence Time Analysis - Results ===\n\n"
    txt_out += "Inputs per timelapse experiment:\n"
    for tau_tl, (counts, total_counts, numFOVs) in counts_dict.items():
        txt_out += f"-  timelapse {tau_tl}s : numFOVs = {numFOVs} | total_numTracks = {total_counts}\n"
    
    txt_out += "\nk_eff values from exponential fitting:\n"
    for tau_tl, (val, err) in keff_dict.items():
        txt_out += f"-  timelapse {tau_tl}s : k_eff = {val:.4f} ± {err:.4f} seconds^-1\n"
    
    txt_out += f"\nCamera integration (exposure time): {tau_int}s\n"

    txt_out += "\nk_off and k_b values from linear fitting:\n"
    txt_out += f"-  Dissociation rate:  k_off = {rates[0]:.4f} ± {linFit_metrics[1]:.4f} seconds^-1\n"
    txt_out += f"-  Photobleaching rate:  k_b = {rates[1]:.4f} seconds^-1\n"
    txt_out += f"-  R^2 = {linFit_metrics[0]:.4f}"

    print(txt_out)

    txt_destination = os.path.join(destination_dir, 'analysis_results.txt')
    with open(txt_destination, 'w') as file:
        file.write(txt_out)
    






# def compute_keffs_cumulative_survival(counts_dict):
#     """
#     Input raw counts for each timelapse interval for calculating keffs.
#     Args:
#     - counts_dict (dict): Dictionary where keys represent tau_tl (unit: seconds)
#       and values represent a list/array of raw counts for each frame (exact lifetime counts).

#     Returns:
#     - keffs_dict (dict): keys are tau_tl and values represent a tuple of (k_eff, k_eff_sd_error)
#     - fig (matplotlib object): plot of the exponential fittings
#     """

#     keff_dict = {}

#     def exp_decay(x, A, k_eff):
#         return A * np.exp(-k_eff * x)

#     fig, ax = plt.subplots()

#     for tau_tl, value in counts_dict.items():
#         counts = np.array(value[0])

#         # Calculate survival fraction from raw counts
#         total = counts.sum()
#         survival = np.array([counts[i:].sum() / total for i in range(len(counts))])

#         actual_x = np.arange(2, len(counts) + 2) * tau_tl  # Frames start at 2 as per your data
#         fit_x = np.linspace(min(actual_x), max(actual_x), 200)

#         # Filter out zero or negative survival values for log transform
#         valid = survival > 0
#         actual_x_valid = actual_x[valid]
#         survival_valid = survival[valid]
#         log_survival = np.log(survival_valid)

#         # Initial guess from linear fit in log space
#         slope, intercept = np.polyfit(actual_x_valid, log_survival, 1)
#         k_eff_guess = -slope
#         A_guess = np.exp(intercept)
#         p0 = [A_guess, k_eff_guess]

#         # Fit the survival fraction data
#         popt, pcov = curve_fit(exp_decay, actual_x, survival, p0=p0)

#         A_fit, k_eff_fit = popt
#         perr = np.sqrt(np.diag(pcov))
#         A_err, k_eff_err = perr

#         keff_dict[tau_tl] = (k_eff_fit, k_eff_err)

#         scatter = ax.scatter(actual_x, survival, label=f'{tau_tl}s data')
#         ax.plot(fit_x, exp_decay(fit_x, A_fit, k_eff_fit),
#                 label=f'{tau_tl}s fit - $k_{{eff}}$ = {k_eff_fit:.2f} ± {k_eff_err:.2g}',
#                 color=scatter.get_facecolors()[0])

#     ax.set_xscale('log')
#     ax.grid(which='both', linestyle='--', linewidth=0.5)
#     ax.set_xlabel(r"$\tau_{\mathrm{tl}}$ (seconds)")
#     ax.set_ylabel("Survival Fraction")
#     ax.legend()
#     plt.show()

#     return keff_dict, fig


    

    