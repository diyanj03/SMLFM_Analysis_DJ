import os
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import cm
import numpy as np
import seaborn as sns
from scipy import stats
from collections import defaultdict
from scipy.stats import mannwhitneyu, shapiro, ttest_ind



def plotAssociationValues(results_dir_list, sample_names, destination_dir):
    """
    Args: 
    - results_dir_list: list of names of results directories to be analysed
    - sample_names: custom names for each dataset in respective order or results_dir_list
    - destination directory to save plot.
    """

    all_data = []

    # Ensure the sample_dirs and sample_names lists are the same length
    if len(results_dir_list) != len(sample_names):
        raise ValueError("The number of directories must match the number of sample names.")

    for results_dir, sample_name in zip(results_dir_list, sample_names):
    
   
        filepath = os.path.join(results_dir, 'Association', 'HistogramFit_best.csv')

        
        if os.path.exists(filepath):
            df = pd.read_csv(filepath)

            
            sample_data = {'source': [sample_name]}

            # Find all columns that start with 'tau_' (e.g., tau_1, tau_2, etc.)
            tau_columns = [col for col in df.columns if col.startswith('tau_')]

            for tau_col in tau_columns:
                # Extract the first row for the tau value (central value)
                tau_value = df.loc[0, tau_col]

              
                tau_lower = df.loc[1, tau_col]
                tau_upper = df.loc[2, tau_col]

                sample_data[f'{tau_col}'] = [tau_value]
                sample_data[f'{tau_col}_lower'] = [tau_lower]
                sample_data[f'{tau_col}_upper'] = [tau_upper]

            
            all_data.append(pd.DataFrame(sample_data))

    # Concatenate all data frames from different directories
    results_df = pd.concat(all_data, ignore_index=True)



    def plotting_association_values(ass_data, destination_dir):
        plt.figure(figsize=(5, 4))  

        tau_columns = [col for col in ass_data.columns if col.startswith('tau_') and not col.endswith('_lower') and not col.endswith('_upper')]

        for tau_col in tau_columns:
            sns.scatterplot(data=ass_data, x='source', y=tau_col, label=tau_col, s=75, marker='X')

            tau_lower = ass_data[f'{tau_col}_lower']
            tau_upper = ass_data[f'{tau_col}_upper']
            plt.errorbar(
                ass_data['source'],
                ass_data[tau_col],
                yerr=[ass_data[tau_col] - tau_lower, tau_upper - ass_data[tau_col]],
                fmt='none',
                capsize=4,
                ecolor='gray' 
            )

        plt.xticks(rotation=45)
        plt.ylabel('Association Time (s)')
        plt.xlabel('')
        plt.legend(title='Tau Values')
        destination_path = os.path.join(destination_dir, '_'.join(sample_names) + '_associationValues.png')
        plt.margins(x=0.3)
        plt.tight_layout()
        plt.savefig(destination_path, dpi=400)
        plt.show()

    # Generate the plot
    plotting_association_values(results_df, destination_dir)



# Percentage of Trajectories confined per FOV

def extracting_confPerc_values(results_directory):
    """
    Args: path of results directory generated by the MATLAB tracking data analysis
    Return: list of confPerc values from PerFOVstats.csv
    """
    perfovstats_filepath = os.path.join(results_directory, 'AllTrajectories', 'PerFOVstats.csv')
    if not os.path.exists(perfovstats_filepath):
        raise FileNotFoundError(f"File not found: {perfovstats_filepath}")
    
    df = pd.read_csv(perfovstats_filepath)

    # Filter out NaNs and negative values
    confPerc_list = df['confPerc']
    confPerc_list = confPerc_list[confPerc_list.notna() & (confPerc_list >= 0)].tolist()

    return confPerc_list

def distribution_confPerc_allFOV(results_dir, molecule_name, destination_dir):
    """
    Args:
    root directory
    user input: name of molecule (string)
    """

    plt.figure(figsize=(8, 3))
    sns.boxplot(x=extracting_confPerc_values(results_dir), width=0.5, color="lightblue", orient='h')
    sns.stripplot(x=extracting_confPerc_values(results_dir), jitter=True, color='black', alpha=0.5, size=5, orient='h')
    plt.title(molecule_name)
    plt.xlabel('Percentage of Confined Trajectories (%)')
    plt.tight_layout()

    # destination_dir = os.path.join(results_dir, 'jitter plots')
    os.makedirs(destination_dir, exist_ok=True)
    destination_path = os.path.join(destination_dir, molecule_name + '_confPerc_boxplot.png')
    plt.savefig(destination_path, dpi = 300)
    plt.show()

def jitter_boxplots_confPerc(results_dir_list, labels, destination_dir, rgb_list=None):
    data_list = []
    means = {}
    stds = {}
    normality_results = {}
    test_results = {}

    for label, dir in zip(labels, results_dir_list):
        confPerc_list = extracting_confPerc_values(dir)
        data_list.append(confPerc_list)
        means[label] = np.mean(confPerc_list)
        stds[label] = np.std(confPerc_list)
        stat, p = shapiro(confPerc_list)
        normality_results[label] = {
            'statistic': stat,
            'p_value': p,
            'normal': p > 0.05
        }

    xs = [np.random.normal(i + 1, 0.04, len(group)) for i, group in enumerate(data_list)]
    
    
    width_per_dataset = 6.4 / 3 
    fig_width = width_per_dataset * len(data_list)
    plt.figure(figsize=(fig_width, 4.8))

   
    if len(data_list) == 2:
        plt.boxplot(
        data_list,
        tick_labels=labels,
        widths = 0.28,
        medianprops=dict(color='black'))
    else:
        plt.boxplot(
        data_list,
        tick_labels=labels,
        medianprops=dict(color='black'))

    plt.ylabel('Percentage of Trajectories Confined per FOV (%)')


    if rgb_list:
        if len(rgb_list) != len(data_list):
            print("number of rgb codes provided doesn't match number of datasets to compare")
        for x, val, rgb in zip(xs, data_list, rgb_list):
            plt.scatter(x, val, color=rgb, alpha=0.4)
    
    else:
        clevels = np.linspace(0., 1., len(data_list))
        for x, val, clevel in zip(xs, data_list, clevels):
            plt.scatter(x, val, color=cm.prism(clevel), alpha=0.4)
        

    def get_significance_symbol(p_value):
        if p_value < 0.0001: return "****"
        elif p_value < 0.001: return "***"
        elif p_value < 0.01: return "**"
        elif p_value < 0.05: return "*"
        else: return "ns"

    y_stacks = defaultdict(int)
    
    max_value = np.max([np.max(data) for data in data_list])
    base_gap = max_value * 0.03  # for example, 3% of the max value
    stack_gap = max_value * 0.05
    text_offset = 0.0

    max_annotation_y = 0

    for i in range(len(data_list)):
        for j in range(i + 1, len(data_list)):
            label_i = labels[i]
            label_j = labels[j]
            normal_i = normality_results[label_i]['normal']
            normal_j = normality_results[label_j]['normal']
            
            if normal_i and normal_j:
                test_name = 't-test'
                stat, p_value = ttest_ind(data_list[i], data_list[j], equal_var=False)
            else:
                test_name = 'mannwhitney'
                stat, p_value = mannwhitneyu(data_list[i], data_list[j], alternative='two-sided')

            sig_symbol = get_significance_symbol(p_value)
            pair_key = f"{label_i} vs {label_j}"
            test_results[pair_key] = {
                'test': test_name,
                'statistic': stat,
                'p_value': p_value,
                'significance': sig_symbol
            }

            x1, x2 = i + 1, j + 1
            base_y = max(np.max(data_list[i]), np.max(data_list[j])) + base_gap
            stack_level = y_stacks[base_y]
            y = base_y + stack_level * stack_gap
            y_stacks[base_y] += 1
            plt.plot([x1, x2], [y, y], color='black', linewidth=1)
            plt.text((x1 + x2) / 2, y + text_offset, sig_symbol, ha='center', va='bottom')
            
            max_annotation_y = max(max_annotation_y, y + text_offset)


    all_values = np.concatenate(data_list)
    padding = 0.1 * (np.max(all_values) - np.min(all_values))
    plt.ylim(np.min(all_values) - padding, max_annotation_y + padding) 


    # Create output directory
    os.makedirs(destination_dir, exist_ok=True)
    plot_path = os.path.join(destination_dir, '_'.join(labels) + '_confPerc_boxplots.pdf')
    plt.savefig(plot_path)
    plt.show()

    # Write summary to .txt
    summary_path = os.path.join(destination_dir, '_'.join(labels) + '_confPerc_summary.txt')
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("=== Percentage confined per FOV Comparison Summary ===\n\n")

        f.write(">> Means (%):\n")
        for label in labels:
            f.write(f"{label}: {means[label]:.5f}\n")
        f.write("\n")

        f.write(">> Standard Deviations (%):\n")
        for label in labels:
            f.write(f"{label}: {stds[label]:.5f}\n")
        f.write("\n")

        f.write(">> Normality Test (Shapiro-Wilk):\n")
        for label in labels:
            res = normality_results[label]
            normal_str = "Normal" if res['normal'] else "Not normal"
            f.write(f"{label}: statistic = {res['statistic']:.4f}, p = {res['p_value']:.4f} â†’ {normal_str}\n")
        f.write("\n")

        f.write(">> Pairwise Significance Tests:\n")
        for pair, res in test_results.items():
            f.write(f"{pair}: {res['test']} | stat = {res['statistic']:.4f}, p = {res['p_value']:.4g}, sig = {res['significance']}\n")



# MEAN UNCONFINED DIFFUSION CONSTANTS per FOV

def extracting_avg_unconf_diffConstants(results_directory):
    """
    Args: path of results directory generated by the matlab tracking data analysis
    Returns:
        - list of mean unconf diffusion constants corresponding to all fovs
        - integer: total number of fovs
        - int: number of fovs that have at least one unconfined trajectory
        - float: mean number of unconf counts per fov  
    """
    diffusionConst_filepath = os.path.join(results_directory, 'Unconfined', 'diffusionConst.csv')
    df = pd.read_csv(diffusionConst_filepath)
    
    np_avg_diffusionConst_list = [] 

    for x in (df['datasetIdx']).unique():
        df_perfov = df[df['datasetIdx'] == x]
        np_avg_diffusionConst_list.append(np.mean(df_perfov['diffusionConst']))
    
    avg_diffusionConst_list = [float(x) for x in np_avg_diffusionConst_list]

    # total number of fovs
    total_number_of_fovs = (df['datasetIdx'].max())

    # number of fovs with unconfined trajectories
    fovs_with_unconfinedcounts = len(df['datasetIdx'].value_counts().tolist())
    
    # mean number of unconfined trajectories amongst fovs that do have at least 1 unconfined trajectory
    mean_unconf_traj_counts = np.mean(df['datasetIdx'].value_counts().tolist())

    return [avg_diffusionConst_list, total_number_of_fovs, fovs_with_unconfinedcounts, mean_unconf_traj_counts]

def distribution_unconf_diffusionConst(results_dir, molecule_name, destination_dir):
    
    plt.figure(figsize=(8, 3))
    sns.boxplot(x=extracting_avg_unconf_diffConstants(results_dir)[0], width=0.5, color="lightblue", orient='h')
    sns.stripplot(x=extracting_avg_unconf_diffConstants(results_dir)[0], jitter=True, color='black', alpha=0.5, size=5, orient='h')
    plt.title(molecule_name)
    plt.xlabel('Mean Unconfined Diffusion Constant per FOV (Î¼m$^2$/s)')
    plt.tight_layout()

    destination_path = os.path.join(destination_dir, molecule_name + '_diffusionConst_boxplot.png')
    plt.savefig(destination_path, dpi = 300)
    plt.show()

def jitter_boxplots_unconf_diffusionConst(results_dir_list, labels, destination_dir, rgb_list=None):
    data_list = []
    means = {}
    stds = {}
    normality_results = {}
    test_results = {}

    for label, dir in zip(labels, results_dir_list):
        diffConst_list = extracting_avg_unconf_diffConstants(dir)[0]
        data_list.append(diffConst_list)
        means[label] = np.mean(diffConst_list)
        stds[label] = np.std(diffConst_list)
        stat, p = shapiro(diffConst_list)
        normality_results[label] = {
            'statistic': stat,
            'p_value': p,
            'normal': p > 0.05
        }

    xs = [np.random.normal(i + 1, 0.04, len(group)) for i, group in enumerate(data_list)]
    
    
    width_per_dataset = 6.4 / 3 
    fig_width = width_per_dataset * len(data_list)
    plt.figure(figsize=(fig_width, 4.8))

    if len(data_list) == 2:
        plt.boxplot(
        data_list,
        tick_labels=labels,
        widths = 0.28,
        medianprops=dict(color='black'))
    else:
        plt.boxplot(
        data_list,
        tick_labels=labels,
        medianprops=dict(color='black'))

    plt.ylabel('Mean Unconfined Diffusion Constant per FOV (Î¼m$^2$/s)')


    if rgb_list:
        if len(rgb_list) != len(data_list):
            print("number of rgb codes provided doesn't match number of datasets to compare")
        for x, val, rgb in zip(xs, data_list, rgb_list):
            plt.scatter(x, val, color=rgb, alpha=0.4)
    
    else:
        clevels = np.linspace(0., 1., len(data_list))
        for x, val, clevel in zip(xs, data_list, clevels):
            plt.scatter(x, val, color=cm.prism(clevel), alpha=0.4)
        

    def get_significance_symbol(p_value):
        if p_value < 0.0001: return "****"
        elif p_value < 0.001: return "***"
        elif p_value < 0.01: return "**"
        elif p_value < 0.05: return "*"
        else: return "ns"

    y_stacks = defaultdict(int)
    
    max_value = np.max([np.max(data) for data in data_list])
    base_gap = max_value * 0.03  # for example, 3% of the max value
    stack_gap = max_value * 0.05
    text_offset = 0.0

    max_annotation_y = 0

    for i in range(len(data_list)):
        for j in range(i + 1, len(data_list)):
            label_i = labels[i]
            label_j = labels[j]
            normal_i = normality_results[label_i]['normal']
            normal_j = normality_results[label_j]['normal']
            
            if normal_i and normal_j:
                test_name = 't-test'
                stat, p_value = ttest_ind(data_list[i], data_list[j], equal_var=False)
            else:
                test_name = 'mannwhitney'
                stat, p_value = mannwhitneyu(data_list[i], data_list[j], alternative='two-sided')

            sig_symbol = get_significance_symbol(p_value)
            pair_key = f"{label_i} vs {label_j}"
            test_results[pair_key] = {
                'test': test_name,
                'statistic': stat,
                'p_value': p_value,
                'significance': sig_symbol
            }

            x1, x2 = i + 1, j + 1
            base_y = max(np.max(data_list[i]), np.max(data_list[j])) + base_gap
            stack_level = y_stacks[base_y]
            y = base_y + stack_level * stack_gap
            y_stacks[base_y] += 1
            plt.plot([x1, x2], [y, y], color='black', linewidth=1)
            plt.text((x1 + x2) / 2, y + text_offset, sig_symbol, ha='center', va='bottom')
            
            max_annotation_y = max(max_annotation_y, y + text_offset)


    all_values = np.concatenate(data_list)
    padding = 0.1 * (np.max(all_values) - np.min(all_values))
    plt.ylim(np.min(all_values) - padding, max_annotation_y + padding) 


    # Create output directory
    os.makedirs(destination_dir, exist_ok=True)
    plot_path = os.path.join(destination_dir, '_'.join(labels) + '_diffusionConst_Unconfined_boxplots.pdf')
    plt.savefig(plot_path, dpi=300)
    plt.show()

    # Write summary to .txt
    summary_path = os.path.join(destination_dir, '_'.join(labels) + '_diffusionConst_Unconfined_summary.txt')
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("=== Unconfined diffConst Comparison Summary ===\n\n")

        f.write(">> Means (Î¼mÂ²/s):\n")
        for label in labels:
            f.write(f"{label}: {means[label]:.5f}\n")
        f.write("\n")

        f.write(">> Standard Deviations (Î¼mÂ²/s):\n")
        for label in labels:
            f.write(f"{label}: {stds[label]:.5f}\n")
        f.write("\n")

        f.write(">> Normality Test (Shapiro-Wilk):\n")
        for label in labels:
            res = normality_results[label]
            normal_str = "Normal" if res['normal'] else "Not normal"
            f.write(f"{label}: statistic = {res['statistic']:.4f}, p = {res['p_value']:.4f} â†’ {normal_str}\n")
        f.write("\n")

        f.write(">> Pairwise Significance Tests:\n")
        for pair, res in test_results.items():
            f.write(f"{pair}: {res['test']} | stat = {res['statistic']:.4f}, p = {res['p_value']:.4g}, sig = {res['significance']}\n")




# MEAN CONFINED DIFFUSION CONSTANTS per FOV

def extracting_avg_conf_diffConstants(results_directory):
    """
    Args: path of results directory generated by the matlab tracking data analysis
    Returns:
        - list of mean conf diffusion constants corresponding to all fovs
        - integer: total number of fovs
        - int: number of fovs that have at least one confined trajectory
        - float: mean number of conf counts per fov  
    """
    diffusionConst_filepath = os.path.join(results_directory, 'Confined', 'diffusionConst.csv')
    df = pd.read_csv(diffusionConst_filepath)
    
    np_avg_diffusionConst_list = [] 

    for x in (df['datasetIdx']).unique():
        df_perfov = df[df['datasetIdx'] == x]
        np_avg_diffusionConst_list.append(np.mean(df_perfov['diffusionConst']))
    
    avg_diffusionConst_list = [float(x) for x in np_avg_diffusionConst_list]

    # total number of fovs
    total_number_of_fovs = (df['datasetIdx'].max())

    # number of fovs with unconfined trajectories
    fovs_with_confinedcounts = len(df['datasetIdx'].value_counts().tolist())
    
    # mean number of unconfined trajectories amongst fovs that do have at least 1 unconfined trajectory
    mean_conf_traj_counts = np.mean(df['datasetIdx'].value_counts().tolist())

    return [avg_diffusionConst_list, total_number_of_fovs, fovs_with_confinedcounts, mean_conf_traj_counts]

def distribution_conf_diffusionConst(results_dir, molecule_name, destination_dir):
    
    plt.figure(figsize=(8, 3))
    sns.boxplot(x=extracting_avg_conf_diffConstants(results_dir)[0], width=0.5, color="lightblue", orient='h')
    sns.stripplot(x=extracting_avg_conf_diffConstants(results_dir)[0], jitter=True, color='black', alpha=0.5, size=5, orient='h')
    plt.title(molecule_name)
    plt.xlabel('Mean Confined Diffusion Constant per FOV (Î¼m$^2$/s)')
    plt.tight_layout()

    destination_path = os.path.join(destination_dir, molecule_name + '_confined_diffusionConst_boxplot.png')
    plt.savefig(destination_path, dpi = 300)
    plt.show()

def jitter_boxplots_conf_diffusionConst(results_dir_list, labels, destination_dir, rgb_list=None):
    data_list = []
    means = {}
    stds = {}
    normality_results = {}
    test_results = {}

    for label, dir in zip(labels, results_dir_list):
        diffConst_list = extracting_avg_conf_diffConstants(dir)[0]
        data_list.append(diffConst_list)
        means[label] = np.mean(diffConst_list)
        stds[label] = np.std(diffConst_list)
        stat, p = shapiro(diffConst_list)
        normality_results[label] = {
            'statistic': stat,
            'p_value': p,
            'normal': p > 0.05
        }

    xs = [np.random.normal(i + 1, 0.04, len(group)) for i, group in enumerate(data_list)]
    
    
    width_per_dataset = 6.4 / 3 
    fig_width = width_per_dataset * len(data_list)
    plt.figure(figsize=(fig_width, 4.8))

    if len(data_list) == 2:
        plt.boxplot(
        data_list,
        tick_labels=labels,
        widths = 0.28,
        medianprops=dict(color='black'))
    else:
        plt.boxplot(
        data_list,
        tick_labels=labels,
        medianprops=dict(color='black'))

    plt.ylabel('Mean Confined Diffusion Constant per FOV (Î¼m$^2$/s)')


    if rgb_list:
        if len(rgb_list) != len(data_list):
            print("number of rgb codes provided doesn't match number of datasets to compare")
        for x, val, rgb in zip(xs, data_list, rgb_list):
            plt.scatter(x, val, color=rgb, alpha=0.4)
    
    else:
        clevels = np.linspace(0., 1., len(data_list))
        for x, val, clevel in zip(xs, data_list, clevels):
            plt.scatter(x, val, color=cm.prism(clevel), alpha=0.4)
        

    def get_significance_symbol(p_value):
        if p_value < 0.0001: return "****"
        elif p_value < 0.001: return "***"
        elif p_value < 0.01: return "**"
        elif p_value < 0.05: return "*"
        else: return "ns"

    y_stacks = defaultdict(int)
    
    max_value = np.max([np.max(data) for data in data_list])
    base_gap = max_value * 0.03  # for example, 3% of the max value
    stack_gap = max_value * 0.05
    text_offset = 0.0

    max_annotation_y = 0

    for i in range(len(data_list)):
        for j in range(i + 1, len(data_list)):
            label_i = labels[i]
            label_j = labels[j]
            normal_i = normality_results[label_i]['normal']
            normal_j = normality_results[label_j]['normal']
            
            if normal_i and normal_j:
                test_name = 't-test'
                stat, p_value = ttest_ind(data_list[i], data_list[j], equal_var=False)
            else:
                test_name = 'mannwhitney'
                stat, p_value = mannwhitneyu(data_list[i], data_list[j], alternative='two-sided')

            sig_symbol = get_significance_symbol(p_value)
            pair_key = f"{label_i} vs {label_j}"
            test_results[pair_key] = {
                'test': test_name,
                'statistic': stat,
                'p_value': p_value,
                'significance': sig_symbol
            }

            x1, x2 = i + 1, j + 1
            base_y = max(np.max(data_list[i]), np.max(data_list[j])) + base_gap
            stack_level = y_stacks[base_y]
            y = base_y + stack_level * stack_gap
            y_stacks[base_y] += 1
            plt.plot([x1, x2], [y, y], color='black', linewidth=1)
            plt.text((x1 + x2) / 2, y + text_offset, sig_symbol, ha='center', va='bottom')
            
            max_annotation_y = max(max_annotation_y, y + text_offset)


    all_values = np.concatenate(data_list)
    padding = 0.1 * (np.max(all_values) - np.min(all_values))
    plt.ylim(np.min(all_values) - padding, max_annotation_y + padding) 


    # Create output directory
    os.makedirs(destination_dir, exist_ok=True)
    plot_path = os.path.join(destination_dir, '_'.join(labels) + '_diffusionConst_Confined_boxplots.pdf')
    plt.savefig(plot_path, dpi=300)
    plt.show()

    # Write summary to .txt
    summary_path = os.path.join(destination_dir, '_'.join(labels) + '_diffusionConst_Confined_summary.txt')
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("=== Confined diffConst Comparison Summary ===\n\n")

        f.write(">> Means (Î¼mÂ²/s):\n")
        for label in labels:
            f.write(f"{label}: {means[label]:.5f}\n")
        f.write("\n")

        f.write(">> Standard Deviations (Î¼mÂ²/s):\n")
        for label in labels:
            f.write(f"{label}: {stds[label]:.5f}\n")
        f.write("\n")

        f.write(">> Normality Test (Shapiro-Wilk):\n")
        for label in labels:
            res = normality_results[label]
            normal_str = "Normal" if res['normal'] else "Not normal"
            f.write(f"{label}: statistic = {res['statistic']:.4f}, p = {res['p_value']:.4f} â†’ {normal_str}\n")
        f.write("\n")

        f.write(">> Pairwise Significance Tests:\n")
        for pair, res in test_results.items():
            f.write(f"{pair}: {res['test']} | stat = {res['statistic']:.4f}, p = {res['p_value']:.4g}, sig = {res['significance']}\n")
